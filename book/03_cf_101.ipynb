{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetCDF Metadata and the CF Conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapter, we learned about the core centent structure of a standard netCDF dataset. It is clear that metadata is an essential component for a netCDF file to be self-described. In this chapter, we are going to learn about the CF Conventions, a widely adopted metadata standard for netCDF files. The first question that may rise is probably, why do we ever want to standardize metadata? To answer this question, let's think about a few situations we may encounter when conducting a research:\n",
    "\n",
    "* I would like to use this and that dataset, where do I find them? \n",
    "\n",
    "* How do I know if there are any other datasets available that can be valuable for my research? And where do I find such datasets?\n",
    "\n",
    "* I want the dataset in a analysis-ready status, ideally suit for joint use with other datasets. If not, how can I transform them for jointly use?\n",
    "\n",
    "And if you are a data provider, you are very likely concerned about\n",
    "\n",
    "* How can I make my dataset possibly land in the hands of users who need it?\n",
    "\n",
    "In the current age, the earth system science (ESS) communities are generating, exchanging, and consuming huge amount of data. On one hand, it's often a challenging task for data users to find the right datasets from an enormous pool of data; on the other hand, data providers also face difficulties to bring their datasets to users. In nowaday's research data management (RDM) ecosystem, enriching and standardizing the metadata of all kinds of data is a basic strategy and an effective practice to meet these challenges, because it largely enhances the foundability of a dataset by machines. Moreover, standardized metadata will also extensively ease the joint use and promote the reusability of data.\n",
    "\n",
    "In a broader sense, metadata standardization can facilitate the achievement of the FAIR principles. \"FAIR\" stands for: \n",
    "\n",
    "1. **Findable**: Data should be easy to find for both *humans* and *computers*. This means data should have a unique identifier and be described with rich metadata.\n",
    "\n",
    "2. **Accessible**: Once found, data should be easy to access, ideally through standardized methods. Even if the data is private, the metadata should be accessible to show the data exists.\n",
    "\n",
    "3. **Interoperable**: Data should be compatible with other data and tools. This means deploying data analysis workflows with different data and tools intergrated is much easier.\n",
    "\n",
    "4. **Reusable**: Data should be well-described and documented so it can be reused in the future. This involves clear usage licenses and detailed information about the data.\n",
    "\n",
    "Research data become more useful and valuable to the scientific community and other users when the FAIR principles are implemented, and metadata standardization is a core practice in implementing the FAIR principles. In the case of netCDF data, the CF Conventions is becoming a widely adopted metadata standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the CF Conventions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, a *metadata standard* is a set of rules or guidelines that defines how metadata should be structured, described, and managed. It specifies the elements or attributes to be included, the semantics of those elements, and often the syntax or format in which the metadata should be encoded. As a metadata standard for netCDF data format, the CF Conventions provide definitions to different variable types in a netCDF dataset (coordinate variable, auxiliary coordinate variable, boundary variable etc.), give guidlines on the content structure of different types of data (grid, point, time series, trajectory, profiles), and standardizes what metadata should be included and how they are annotated.\n",
    "\n",
    "At first, let's make it clear that the CF Conventions is not the only metadata standard for netCDF files. Its accessor, the COARDS Conventions, is for example a widely implemented metadata standard too. Sometimes big data providers also have their own metadata standards. However, the CF Conventions is becoming more and more popular in the community by showing its good flexibility and compatibility with other standards. For instance, the COARDS Conventions places rigid restriction on the order of dimensions while the CF Conventions doesn't. And as a successor of the COARDS Conventions, the CF Conventions is *backward compatible* with COARDS, which means programs that can process CF conforming datasets should likely be able to process COARDS conforming datasets too.\n",
    "\n",
    "Now let's take a closer look at how the CF Conventions formulates the metadata in a netCDF file with an example [dataset](https://www.unidata.ucar.edu/software/netcdf/examples/tos_O1_2001-2002.nc) that contains sea surface temperatures collected by [PCMDI](https://en.wikipedia.org/wiki/Program_for_Climate_Model_Diagnosis_and_Intercomparison)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\tlon = 180 ;\n",
      "\tbnds = 2 ;\n",
      "\tlat = 170 ;\n",
      "\ttime = 24 ;\n",
      "\n",
      "variables:\n",
      "\tfloat64 lon(lon) ;\n",
      "\t\tlon:standard_name = longitude ;\n",
      "\t\tlon:long_name = longitude ;\n",
      "\t\tlon:units = degrees_east ;\n",
      "\t\tlon:axis = X ;\n",
      "\t\tlon:bounds = lon_bnds ;\n",
      "\t\tlon:original_units = degrees_east ;\n",
      "\tfloat64 lon_bnds(lon, bnds) ;\n",
      "\tfloat64 lat(lat) ;\n",
      "\t\tlat:standard_name = latitude ;\n",
      "\t\tlat:long_name = latitude ;\n",
      "\t\tlat:units = degrees_north ;\n",
      "\t\tlat:axis = Y ;\n",
      "\t\tlat:bounds = lat_bnds ;\n",
      "\t\tlat:original_units = degrees_north ;\n",
      "\tfloat64 lat_bnds(lat, bnds) ;\n",
      "\tfloat64 time(time) ;\n",
      "\t\ttime:standard_name = time ;\n",
      "\t\ttime:long_name = time ;\n",
      "\t\ttime:units = days since 2001-1-1 ;\n",
      "\t\ttime:axis = T ;\n",
      "\t\ttime:calendar = 360_day ;\n",
      "\t\ttime:bounds = time_bnds ;\n",
      "\t\ttime:original_units = seconds since 2001-1-1 ;\n",
      "\tfloat64 time_bnds(time, bnds) ;\n",
      "\tfloat32 tos(time, lat, lon) ;\n",
      "\t\ttos:standard_name = sea_surface_temperature ;\n",
      "\t\ttos:long_name = Sea Surface Temperature ;\n",
      "\t\ttos:units = K ;\n",
      "\t\ttos:cell_methods = time: mean (interval: 30 minutes) ;\n",
      "\t\ttos:_FillValue = 1.0000000200408773e+20 ;\n",
      "\t\ttos:missing_value = 1.0000000200408773e+20 ;\n",
      "\t\ttos:original_name = sosstsst ;\n",
      "\t\ttos:original_units = degC ;\n",
      "\t\ttos:history =  At   16:37:23 on 01/11/2005: CMOR altered the data in the following ways: added 2.73150E+02 to yield output units;  Cyclical dimension was output starting at a different lon; ;\n",
      "\n",
      "// global attributes:\n",
      "\t:title = IPSL  model output prepared for IPCC Fourth Assessment SRES A2 experiment ;\n",
      "\t:institution = IPSL (Institut Pierre Simon Laplace, Paris, France) ;\n",
      "\t:source = IPSL-CM4_v1 (2003) : atmosphere : LMDZ (IPSL-CM4_IPCC, 96x71x19) ; ocean ORCA2 (ipsl_cm4_v1_8, 2x2L31); sea ice LIM (ipsl_cm4_v ;\n",
      "\t:contact = Sebastien Denvil, sebastien.denvil@ipsl.jussieu.fr ;\n",
      "\t:project_id = IPCC Fourth Assessment ;\n",
      "\t:table_id = Table O1 (13 November 2004) ;\n",
      "\t:experiment_id = SRES A2 experiment ;\n",
      "\t:realization = 1 ;\n",
      "\t:cmor_version = 0.9599999785423279 ;\n",
      "\t:Conventions = CF-1.0 ;\n",
      "\t:history = YYYY/MM/JJ: data generated; YYYY/MM/JJ+1 data transformed  At 16:37:23 on 01/11/2005, CMOR rewrote data to comply with CF standards and IPCC Fourth Assessment requirements ;\n",
      "\t:references = Dufresne et al, Journal of Climate, 2015, vol XX, p 136 ;\n",
      "\t:comment = Test drive ;\n",
      "}"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(\"/Users/icdc/Documents/NFDI/Kemeng/cfbook/src/data/tos_O1_2001-2002.nc\",\n",
    "                     decode_cf=False)\n",
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetCDF Metadata complied with the CF Conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Attributes\n",
    "\n",
    "In the CF Conventions, metadata are considered as \"required\" or \"optional\".\n",
    "\n",
    "For all kinds of variables, the attribute `units` and at least one of the attribute `long_name` and `standard_name` are required. Both `long_name` and `standard_name` tell what the variable is; `standard_name` must be a controlled vocabulary as defined in the [\"CF Standard Name Table\"](https://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html), while `long_name` allows data providers to name the variable on their own. If a variable has a `standard_name`, its `units` can be looked up in the \"CF Standard Name Table\" as well. In case a variable cannot be named by a term from the \"CF Standard Name Table\", data providers should name it under `long_name` and provide a `units` that's parsable by the UDUNITS library.\n",
    "\n",
    "As you can see, the example dataset contains three coordinate variables: `lon`, `lat`, and `time`. As regulated in the CF Conventions, a variable representing the longitude must literally have \"longitude\" as `standard_name` and \"degrees_east\" as `units`; similarly, the `standard_name` and `units` for a latitude variable must be \"latitude\" and \"degrees_north\". As for the time variable, it must have \"time\" as `standard_name` and a string similar to the form of \"[time-interval] since YYYY-MM-DD hh:mm:ss\" as `units`, e.g. in our example the unit of the time variable is \"seconds since 2001-1-1\". \"seconds\", \"minutes\", \"hours\", and \"days\" are the most commonly used time intervals; it is not recommended to use \"months\" or \"years\" as the length of these time intervals can vary. If you aren't yet familiar with \"coordinate variable\" in a netCDF file, you can learn about it in the [previous chapter](netcdf_101.ipynb).\n",
    "\n",
    "axis, bounds, \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to a coordinate variable, a data variable also requires the attribute `units` and at least one of `long_name` and `standard_name`. Other common attributes for a data variable include:\n",
    "\n",
    "* `cell_methods`: records the method used to derive data that represents the cell values\n",
    "\n",
    "* `_FillValue`: A value used to represent missing or undefined data. Not allowed for coordinate variables but allowed for auxiliary coordinate variables.\n",
    "\n",
    "* `missing_value`: A value or values used to represent missing or undefined data. Not allowed for coordinate variables but allowed for auxiliary coordinate variables.\n",
    "\n",
    "* `history`: List of the applications that hvae modified the original data. Usually appear as global attribute\n",
    "\n",
    "* `coordinates`: List of names of auxiliary coordinate variables (and optionally coordinate variables) separated by a blank. There is no restriction on the order in which the variable names appear in the string. [excerpt](https://docs.unidata.ucar.edu/netcdf-c/current/attribute_conventions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some optional attributes can be attached to both data variable and coordinate variable, like `source`, `references`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Attributes\n",
    "\n",
    "* title: short description of the file contents\n",
    "\n",
    "* intitution: Where the original data was produced.\n",
    "\n",
    "* source: method of production of the original data.\n",
    "\n",
    "* Conventions: Name of the conventions followed by the dataset\n",
    "\n",
    "* references: References that describe the data or methods used to produce it.\n",
    "\n",
    "One of the important global attributes to be included is `Convention`, which points the metadata convention applied to this dataset. A metadata convention standardizes the formulation of the metadata in a dataset, thus is a crucial component to make a dataset more aligned with the [FAIR principle](https://www.nature.com/articles/sdata201618)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full version of the usual attributes in the CF Conventions are available in the [documentation](https://cfconventions.org/Data/cf-conventions/cf-conventions-1.11/cf-conventions.html#attribute-appendix) of the CF Convensions.\n",
    "\n",
    "There are some attributes specific to the dataset, such as calendar, original_units for coordinate variable and data variable; contact, project_id, cmor_version in global variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "It should be noted that including attributes that are not specified in the CF Conventions doesn't make a dataset incompatible with the CF Conventions.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Chapter\n",
    "\n",
    "Here is a [reference to the intro](00_intro.md).\n",
    "\n",
    "Here is a reference to the [previous chapter](section-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvnetcdf",
   "language": "python",
   "name": "venvnetcdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
